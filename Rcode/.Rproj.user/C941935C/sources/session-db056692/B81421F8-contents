---
title: "Untitled"
output: html_document
date: "2025-04-09"
---

Install any packages that will be used for this project
```{r, message = FALSE, warning = FALSE}
if(!require(readxl)){install.packages("readxl")}
library(readxl)
if(!require(dplyr)){install.packages("dplyr")}
library(dplyr)
if(!require(lubridate)){install.packages("lubridate")}
library(lubridate)
if(!require(tidyverse)){install.packages("tidyverse")}
library(tidyverse)
if (!require(glmnet)) install.packages("glmnet")
library(glmnet)

```

\text{========================================================================}\
Data Wrangling\
Read the data in to the environment
```{r, message = FALSE, warning = FALSE}
load("data_ml.RData")                   # Load the data
head(data_ml, 6)
```
The first column is a unique identifier for each stock and the second column is the observation date. The other columns are financial or fundamental features for example, Advt_12M_Usd would represents average trading volume over the past 12 months (in USD).\

Cleanning the data
```{r}
data_ml <- data_ml %>%
  distinct() %>% #remove duplicates
  filter(date > "1999-12-31",         # Keep the date with sufficient data points
         date < "2019-01-01") %>%
    arrange(stock_id, date)             # Order the data
```

Now we are going to create a new column "target_return" to store our predicted future stock returns
```{r}
data_ml <- data_ml %>%
  mutate(target_return = R1M_Usd) %>%
  filter(!is.na(target_return))  # Remove rows without a future return
```

Then We define our train samples as the following:\
Training set: from 2000-01-01 to 2013-12-31\
Validation set: from 2014-01-01 to 2016-12-31\
Testing Set: from 2017-01-01 to 2018-12-31\
```{r}
training_set <- filter(data_ml, date < as.Date("2014-01-15"))
validation_set <- filter(data_ml, (date >= as.Date("2014-01-15") 
                                   & date < as.Date("2017-01-15")))
testing_set <- filter(data_ml, date >= as.Date("2017-01-15"))
```

<!-- Scaling required? -->
Prepare data matrices
```{r}
features <- training_set %>%
  select(-stock_id, -date, -R1M_Usd, -R3M_Usd, -R6M_Usd, -R12M_Usd, -target_return) %>%
  colnames()

# Step 2b: Create X and y matrices
X_train <- as.matrix(training_set[, features])
y_train <- training_set$target_return

X_val <- as.matrix(validation_set[, features])
y_val <- validation_set$target_return

X_test <- as.matrix(testing_set[, features])
y_test <- testing_set$target_return
```

Train Lasso with cross-validation
```{r}
# Use 10-fold cross-validation to find optimal lambda
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)

# Plot cross-validation curve
plot(cv_lasso)

# Get best lambda
best_lambda <- cv_lasso$lambda.min
cat("Best lambda:", best_lambda, "\n")

```

Evaluate model on validation
```{r}
# Predict on validation and test sets
pred_val <- predict(cv_lasso, s = best_lambda, newx = X_val)
pred_test <- predict(cv_lasso, s = best_lambda, newx = X_test)

# Compute RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

cat("Validation RMSE:", rmse(y_val, pred_val), "\n")
cat("Test RMSE:", rmse(y_test, pred_test), "\n")

```

View selected features
```{r}
# Extract coefficients at best lambda
lasso_coef <- coef(cv_lasso, s = best_lambda)
nonzero <- lasso_coef[lasso_coef[, 1] != 0, ]
print(nonzero)

```



